{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (2.1.0)\n","Requirement already satisfied: tensorboardX in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (2.6.2.2)\n","Requirement already satisfied: tensorboard in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (2.15.1)\n","Requirement already satisfied: pandas in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (2.1.2)\n","Requirement already satisfied: filelock in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from torch) (4.8.0)\n","Requirement already satisfied: sympy in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from torch) (2023.10.0)\n","Requirement already satisfied: numpy in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboardX) (1.26.1)\n","Requirement already satisfied: packaging in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboardX) (23.2)\n","Requirement already satisfied: protobuf>=3.20 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboardX) (4.23.4)\n","Requirement already satisfied: absl-py>=0.4 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (2.0.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (1.59.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (2.23.4)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (1.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (65.5.0)\n","Requirement already satisfied: six>1.9 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from tensorboard) (3.0.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from pandas) (2023.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /Users/fx7707/.Kaggle/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install torch tensorboardX tensorboard pandas"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from tensorboardX import SummaryWriter"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","class CustomDataSet(Dataset):\n","    def __init__(self, x,y):\n","        self.data = x\n","        self.label = y\n","        \n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","    def __getitem__(self, index):\n","        data = self.data[index]\n","        label = self.label[index]\n","\n","        return data, label"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class Net(nn.Module):\n","  def __init__(self,input_shape, modelWidth = 1024):\n","    super(Net,self).__init__()\n","    self.fc1 = nn.Linear(input_shape,modelWidth)\n","    self.fc2 = nn.Linear(modelWidth,modelWidth)\n","    self.fc3 = nn.Linear(modelWidth,1)\n","  def forward(self,x):\n","    x = torch.relu(self.fc1(x))\n","    x = torch.relu(self.fc2(x))\n","    x = torch.sigmoid(self.fc3(x))\n","    return x\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(891, 10)\n"]}],"source":["csv_file_path = \"./dataset/train_preprocessed.csv\"\n","df = pd.read_csv(csv_file_path)\n","y = df[\"Survived\"].values\n","df = df.drop(\"Survived\", axis=1)\n","x = df.values\n","\n","print(x.shape)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Lets create an object from our custom dataset class\n","train_data_object = CustomDataSet(x,y)\n","\n","# Now lets use Data loader to load the data in batches\n","train_loader = torch.utils.data.DataLoader(\n","        train_data_object,\n","        batch_size=128,\n","        shuffle=False\n","    )"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# train_features, train_labels = next(iter(train_loader))\n","# print(f\"Feature batch shape: {train_features.size()}\")\n","# print(f\"Labels batch shape: {train_labels.size()}\")\n","# # print(train_features,train_labels)\n","# testModel = Net(20)\n","# train_features = train_features.to(torch.float32)\n","# output = testModel(train_features)\n","# output = torch.round(output)\n","# print(output)\n","# print(train_labels)\n","# print(output.eq(train_labels.data.view_as(output)).cpu().sum())"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["model = Net(x.shape[1])\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","loss_fn = nn.BCELoss()\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def train(model,epochs = 10, model_path = \"./model.pth\",log_path = \"./log_pytorch/\"):\n","    tb = SummaryWriter(log_path)\n","\n","    # put the model into training mode\n","    model.train()\n","    for epoch in range(1, epochs + 1):\n","        correct = 0\n","\n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            \n","            data = data.to(torch.float32)\n","            # print(\"data\",data)\n","            target = target.to(torch.float32)\n","            target = target.unsqueeze(1)\n","            #calculate output\n","            output = model(data)\n","            # print(output)\n","            #calculate loss\n","            loss = loss_fn(output,target)\n","        \n","            #accuracy\n","            predicted = model(torch.tensor(x,dtype=torch.float32))\n","            acc = (predicted.reshape(-1).detach().numpy().round() == y).mean()\n","            #backprop\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            if batch_idx % 100 == 0:\n","                # losses.append(loss)\n","                # accur.append(acc)\n","                print(\"epoch {}\\tloss : {}\\tAcc: {}\".format(epoch,loss,acc))\n","\n","        tb.add_scalar(\"epoch loss\", loss.item(), epoch)\n","        tb.add_scalar(\"epoch accuracy\", acc, epoch)\n","        for name, weight in model.named_parameters():\n","            tb.add_histogram(name, weight, epoch)\n","            tb.add_histogram(f'{name}.grad',weight.grad, epoch)\n","    # save the model to a .pth file\n","    print('Saving NN to %s' % model_path)\n","    torch.save(model.state_dict(), model_path)\n","    # add graph to tensorboard\n","    tb.add_graph(model, (data,))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def test(model, model_path=\"./model.pth\",testDataPath = \"./dataset/test_preprocessed.csv\"):\n","\n","    df = pd.read_csv(testDataPath)\n","    yt = df[\"PassengerId\"]\n","    df = df.drop(\"PassengerId\", axis=1)\n","    xt = df.values\n","\n","    model.load_state_dict(torch.load(model_path))\n","    \n","    # put model into test mode\n","    model.eval()\n","    with torch.no_grad():\n","    \n","        output = model(torch.tensor(xt,dtype=torch.float32))\n","        pred = output.reshape(-1).detach().numpy().round()\n","        label = yt.values\n","        \n","        result = {\"PassengerId\" : label,\n","                  \"Survived\" : pred}\n","        \n","        return result"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch 1\tloss : 0.6848648190498352\tAcc: 0.6161616161616161\n","epoch 2\tloss : 0.5985071659088135\tAcc: 0.6576879910213244\n","epoch 3\tloss : 0.5608227252960205\tAcc: 0.755331088664422\n","epoch 4\tloss : 0.5341880321502686\tAcc: 0.7822671156004489\n","epoch 5\tloss : 0.5174116492271423\tAcc: 0.7811447811447811\n","epoch 6\tloss : 0.5076558589935303\tAcc: 0.7890011223344556\n","epoch 7\tloss : 0.5022929906845093\tAcc: 0.8047138047138047\n","epoch 8\tloss : 0.4990037977695465\tAcc: 0.8069584736251403\n","epoch 9\tloss : 0.49664175510406494\tAcc: 0.8069584736251403\n","epoch 10\tloss : 0.49499496817588806\tAcc: 0.8069584736251403\n","epoch 11\tloss : 0.4935717284679413\tAcc: 0.8069584736251403\n","epoch 12\tloss : 0.49226856231689453\tAcc: 0.8069584736251403\n","epoch 13\tloss : 0.4911797046661377\tAcc: 0.8069584736251403\n","epoch 14\tloss : 0.4901178479194641\tAcc: 0.8069584736251403\n","epoch 15\tloss : 0.4890228807926178\tAcc: 0.8080808080808081\n","epoch 16\tloss : 0.48799237608909607\tAcc: 0.8080808080808081\n","epoch 17\tloss : 0.4869036078453064\tAcc: 0.8080808080808081\n","epoch 18\tloss : 0.4860759377479553\tAcc: 0.8080808080808081\n","epoch 19\tloss : 0.48528921604156494\tAcc: 0.8080808080808081\n","epoch 20\tloss : 0.484408438205719\tAcc: 0.8080808080808081\n","epoch 21\tloss : 0.4838237762451172\tAcc: 0.8080808080808081\n","epoch 22\tloss : 0.48306578397750854\tAcc: 0.8080808080808081\n","epoch 23\tloss : 0.4824485778808594\tAcc: 0.8080808080808081\n","epoch 24\tloss : 0.4818136692047119\tAcc: 0.8080808080808081\n","epoch 25\tloss : 0.48125261068344116\tAcc: 0.8069584736251403\n","epoch 26\tloss : 0.48047417402267456\tAcc: 0.8069584736251403\n","epoch 27\tloss : 0.47998046875\tAcc: 0.8069584736251403\n","epoch 28\tloss : 0.4794664978981018\tAcc: 0.8069584736251403\n","epoch 29\tloss : 0.47905591130256653\tAcc: 0.8069584736251403\n","epoch 30\tloss : 0.4785560965538025\tAcc: 0.8069584736251403\n","epoch 31\tloss : 0.47816765308380127\tAcc: 0.8069584736251403\n","epoch 32\tloss : 0.47761672735214233\tAcc: 0.8069584736251403\n","epoch 33\tloss : 0.47737473249435425\tAcc: 0.8069584736251403\n","epoch 34\tloss : 0.47689342498779297\tAcc: 0.8069584736251403\n","epoch 35\tloss : 0.47652822732925415\tAcc: 0.8069584736251403\n","epoch 36\tloss : 0.476262629032135\tAcc: 0.8069584736251403\n","epoch 37\tloss : 0.4758802056312561\tAcc: 0.8069584736251403\n","epoch 38\tloss : 0.4757588505744934\tAcc: 0.8069584736251403\n","epoch 39\tloss : 0.4753674864768982\tAcc: 0.8069584736251403\n","epoch 40\tloss : 0.47495973110198975\tAcc: 0.8069584736251403\n","epoch 41\tloss : 0.47465628385543823\tAcc: 0.8069584736251403\n","epoch 42\tloss : 0.47433847188949585\tAcc: 0.8069584736251403\n","epoch 43\tloss : 0.4741615653038025\tAcc: 0.8069584736251403\n","epoch 44\tloss : 0.4739305078983307\tAcc: 0.8069584736251403\n","epoch 45\tloss : 0.47369474172592163\tAcc: 0.8069584736251403\n","epoch 46\tloss : 0.47341102361679077\tAcc: 0.8080808080808081\n","epoch 47\tloss : 0.47319459915161133\tAcc: 0.8080808080808081\n","epoch 48\tloss : 0.4730015993118286\tAcc: 0.8080808080808081\n","epoch 49\tloss : 0.47272926568984985\tAcc: 0.8080808080808081\n","epoch 50\tloss : 0.4724644422531128\tAcc: 0.8080808080808081\n","epoch 51\tloss : 0.47256046533584595\tAcc: 0.8080808080808081\n","epoch 52\tloss : 0.47209587693214417\tAcc: 0.8080808080808081\n","epoch 53\tloss : 0.4721202254295349\tAcc: 0.8080808080808081\n","epoch 54\tloss : 0.4718548059463501\tAcc: 0.8080808080808081\n","epoch 55\tloss : 0.4715088903903961\tAcc: 0.8080808080808081\n","epoch 56\tloss : 0.4714454412460327\tAcc: 0.8080808080808081\n","epoch 57\tloss : 0.47120705246925354\tAcc: 0.8080808080808081\n","epoch 58\tloss : 0.47119075059890747\tAcc: 0.8080808080808081\n","epoch 59\tloss : 0.4711873531341553\tAcc: 0.8080808080808081\n","epoch 60\tloss : 0.4708058536052704\tAcc: 0.8080808080808081\n","epoch 61\tloss : 0.47069573402404785\tAcc: 0.8080808080808081\n","epoch 62\tloss : 0.47018009424209595\tAcc: 0.8114478114478114\n","epoch 63\tloss : 0.47015219926834106\tAcc: 0.8114478114478114\n","epoch 64\tloss : 0.46994563937187195\tAcc: 0.8114478114478114\n","epoch 65\tloss : 0.46984466910362244\tAcc: 0.8114478114478114\n","epoch 66\tloss : 0.4697418808937073\tAcc: 0.8114478114478114\n","epoch 67\tloss : 0.4697098731994629\tAcc: 0.8114478114478114\n","epoch 68\tloss : 0.46946585178375244\tAcc: 0.8114478114478114\n","epoch 69\tloss : 0.46940529346466064\tAcc: 0.8114478114478114\n","epoch 70\tloss : 0.46925339102745056\tAcc: 0.8114478114478114\n","epoch 71\tloss : 0.46905049681663513\tAcc: 0.8114478114478114\n","epoch 72\tloss : 0.4689383804798126\tAcc: 0.8114478114478114\n","epoch 73\tloss : 0.4690438210964203\tAcc: 0.8114478114478114\n","epoch 74\tloss : 0.46884942054748535\tAcc: 0.8114478114478114\n","epoch 75\tloss : 0.4689173698425293\tAcc: 0.8114478114478114\n","epoch 76\tloss : 0.46867817640304565\tAcc: 0.8114478114478114\n","epoch 77\tloss : 0.4687306880950928\tAcc: 0.8114478114478114\n","epoch 78\tloss : 0.46836695075035095\tAcc: 0.8114478114478114\n","epoch 79\tloss : 0.4686499536037445\tAcc: 0.8114478114478114\n","epoch 80\tloss : 0.46831226348876953\tAcc: 0.8114478114478114\n","epoch 81\tloss : 0.46793726086616516\tAcc: 0.8114478114478114\n","epoch 82\tloss : 0.46808820962905884\tAcc: 0.8114478114478114\n","epoch 83\tloss : 0.4679515063762665\tAcc: 0.8114478114478114\n","epoch 84\tloss : 0.4681176245212555\tAcc: 0.8114478114478114\n","epoch 85\tloss : 0.46802908182144165\tAcc: 0.8114478114478114\n","epoch 86\tloss : 0.46774405241012573\tAcc: 0.8114478114478114\n","epoch 87\tloss : 0.4676888585090637\tAcc: 0.8114478114478114\n","epoch 88\tloss : 0.4677037000656128\tAcc: 0.8114478114478114\n","epoch 89\tloss : 0.4675368070602417\tAcc: 0.8114478114478114\n","epoch 90\tloss : 0.46747446060180664\tAcc: 0.8114478114478114\n","epoch 91\tloss : 0.46746569871902466\tAcc: 0.8114478114478114\n","epoch 92\tloss : 0.4676630198955536\tAcc: 0.8114478114478114\n","epoch 93\tloss : 0.4671109616756439\tAcc: 0.8114478114478114\n","epoch 94\tloss : 0.46719974279403687\tAcc: 0.8114478114478114\n","epoch 95\tloss : 0.46705347299575806\tAcc: 0.8114478114478114\n","epoch 96\tloss : 0.4671349823474884\tAcc: 0.8114478114478114\n","epoch 97\tloss : 0.46695756912231445\tAcc: 0.8114478114478114\n","epoch 98\tloss : 0.46715646982192993\tAcc: 0.8114478114478114\n","epoch 99\tloss : 0.4667540192604065\tAcc: 0.8114478114478114\n","epoch 100\tloss : 0.4666319489479065\tAcc: 0.8114478114478114\n","Saving NN to ./model.pth\n"]}],"source":["\n","train(model,epochs=100,model_path=\"./model.pth\",log_path=\"./log_wide/\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["10\n"]}],"source":["testModel = Net(x.shape[1])\n","print(x.shape[1])\n","mapped = test(testModel,model_path=\"./model.pth\",testDataPath = \"./dataset/test_preprocessed.csv\")\n","df = pd.DataFrame.from_dict(mapped)\n","df[\"Survived\"] = df[\"Survived\"].astype(int)\n","df.to_csv(\"./dataset/result.csv\",index=False)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":".Kaggle","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":2}
